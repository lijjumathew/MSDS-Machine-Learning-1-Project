{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages lik numpy, pandas, math plot and seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif, RFE, SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lijjumathew/MSDS-Machine-Learning-1-Project/master/dataset/Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Cleanup & Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.73463\n",
       "1    0.26537\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ideally SeniorCitizen column should be a factor, so let's convert 1,0 values to Yes,No and later we can label encode all factor columns\n",
    "df.SeniorCitizen=df.SeniorCitizen.apply(lambda x: 'Yes' if x==1 else 'No')\n",
    "\n",
    "# Getting rid of unwanted columns like Customer Id.\n",
    "if 'customerID' in df:\n",
    "    del df['customerID']\n",
    "    \n",
    "# converting TotalCharges object dataset into numeric\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors = 'coerce')\n",
    "\n",
    "# Replacing blank values with nulls.\n",
    "df=df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Total charges has some blank values/missing values and needs to be imputed. Filling the missing values\n",
    "df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].mean(), inplace=True)\n",
    "\n",
    "# Consolidate MultipleLines attribute\n",
    "df['MultipleLines'] = df['MultipleLines'].replace('No phone service','No')\n",
    "\n",
    "# Change all values of 'No internet service' to 'No'\n",
    "df = df.replace('No internet service','No')\n",
    "\n",
    "# Replace all yes/no values with 1/0\n",
    "df = df.replace(to_replace=['Yes','No'], value=[1,0])\n",
    "\n",
    "# Create dummy variables in the entire dataset\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# check the distribution\n",
    "df['Churn'].value_counts()/df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the churn results from the dataset\n",
    "y = df['Churn'].values\n",
    "x = df.drop(columns = ['Churn'])\n",
    "\n",
    "# Set features\n",
    "features = x.columns.values\n",
    "\n",
    "# Normalize values\n",
    "scale = MinMaxScaler(feature_range = (0,1))\n",
    "scale.fit(x)\n",
    "x = pd.DataFrame(scale.transform(x))\n",
    "x.columns = features\n",
    "\n",
    "# Set up train/test split with 80/20 ratio\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Approach\n",
    "\n",
    "**Objective** : The main objective of the study is to predict churn\n",
    "\n",
    "Our model building approach is to first run feature selection, iterate multiple models using features selected using below methods and then do hypertuning. This approach is followed for both Logistic Regression and SVM Models. <br><br>\n",
    "**1. Feature Selection** using following methods <br>\n",
    "    1. Removing features using low variance.\n",
    "    2. Univariate feature selection.\n",
    "    3. Recursive feature eliminiation.\n",
    "    4. Select from Model.\n",
    "**2. Hyper Tuning** using following methods <br>\n",
    "    1. Weighted tuning\n",
    "    2. Weights grid search\n",
    "    \n",
    "We have to take into account having an imbalanced dataset. The percentage of data with churn is 26% and with out churn is 73%. Also, our goal is to predict customer who churn with better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected using low variance elimination : \n",
      " ['Partner', 'Dependents', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'gender_Female', 'gender_Male', 'InternetService_DSL', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'PaymentMethod_Electronic check']\n"
     ]
    }
   ],
   "source": [
    "# 1. Removing features using low variance.\n",
    "def variance_threshold_selector(data, threshold=0):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    mask = selector.get_support()\n",
    "    low_var_features = [] \n",
    "    feature_names = list(data.columns.values)\n",
    "    for bool, feature in zip(mask, feature_names):\n",
    "        if bool:\n",
    "            low_var_features.append(feature)\n",
    "    return low_var_features\n",
    "\n",
    "# Ran with tresholds of 0,0.1,0.2,0.3,0.4 and looks like threshold of 0.2 gives optimal number of features.\n",
    "variance_features = variance_threshold_selector(x_train,0.2)\n",
    "print(\"Features selected using low variance elimination : \\n\", variance_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected using Univariate selection : \n",
      " ['tenure', 'MonthlyCharges', 'TotalCharges', 'InternetService_0', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_Two year', 'PaymentMethod_Electronic check']\n"
     ]
    }
   ],
   "source": [
    "# 2. Univariate Selection\n",
    "sel_mutual = SelectKBest(mutual_info_classif, k=8)\n",
    "x_train_mutual = sel_mutual.fit_transform(x_train, y_train)\n",
    "\n",
    "mask = sel_mutual.get_support()\n",
    "univariate_features = [] \n",
    "feature_names = list(x_train.columns.values)\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        univariate_features.append(feature)\n",
    "print(\"Features selected using Univariate selection : \\n\", univariate_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected using recursive elimination: \n",
      " ['tenure', 'StreamingTV', 'StreamingMovies', 'MonthlyCharges', 'TotalCharges', 'InternetService_0', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_Two year', 'PaymentMethod_Electronic check']\n"
     ]
    }
   ],
   "source": [
    "# 3. Recursive Feature Eliminiation\n",
    "\n",
    "model_logistic = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "sel_rfe_logistic = RFE(estimator=model_logistic, n_features_to_select=10, step=1)\n",
    "x_train_rfe_logistic = sel_rfe_logistic.fit_transform(x_train, y_train)\n",
    "\n",
    "mask = sel_rfe_logistic.get_support()\n",
    "recursive_elim_features = [] \n",
    "feature_names = list(x_train.columns.values)\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        recursive_elim_features.append(feature)\n",
    "print(\"Features selected using recursive elimination: \\n\", recursive_elim_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected using select from model method : \n",
      " ['tenure', 'StreamingTV', 'StreamingMovies', 'MonthlyCharges', 'TotalCharges', 'InternetService_0', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_Two year', 'PaymentMethod_Electronic check']\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature selection using SelectFromModel\n",
    "model_logistic = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000, penalty='l1')\n",
    "sel_model_logistic = SelectFromModel(estimator=model_logistic)\n",
    "x_train_sfm_l1 = sel_model_logistic.fit_transform(x_train, y_train)\n",
    "\n",
    "mask = sel_rfe_logistic.get_support()\n",
    "select_from_features = [] \n",
    "feature_names = list(x_train.columns.values)\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        select_from_features.append(feature)\n",
    "print(\"Features selected using select from model method : \\n\", select_from_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Accuracy:  0.7998580553584103\n",
      "Model 1 - ROC:  0.7185991622729045\n",
      "Model 1 - Recall Score:  0.538860103626943\n",
      "Model 1 - Confusion Matrix: \n",
      " [[919 104]\n",
      " [178 208]]\n",
      "Model 1 - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1023\n",
      "           1       0.67      0.54      0.60       386\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.75      0.72      0.73      1409\n",
      "weighted avg       0.79      0.80      0.79      1409\n",
      "\n",
      "Model 1 - Weights:\n",
      " TotalCharges                               0.987159\n",
      "InternetService_Fiber optic                0.822797\n",
      "Contract_Month-to-month                    0.698867\n",
      "PaperlessBilling                           0.371334\n",
      "PaymentMethod_Electronic check             0.292634\n",
      "MultipleLines                              0.240501\n",
      "SeniorCitizen                              0.233807\n",
      "StreamingTV                                0.181166\n",
      "StreamingMovies                            0.180732\n",
      "gender_Female                              0.016114\n",
      "InternetService_DSL                        0.014568\n",
      "Contract_One year                          0.007922\n",
      "MonthlyCharges                             0.000813\n",
      "gender_Male                               -0.015305\n",
      "PaymentMethod_Mailed check                -0.020220\n",
      "DeviceProtection                          -0.023484\n",
      "Partner                                   -0.056451\n",
      "PaymentMethod_Credit card (automatic)     -0.118700\n",
      "Dependents                                -0.131897\n",
      "OnlineBackup                              -0.138956\n",
      "PaymentMethod_Bank transfer (automatic)   -0.152906\n",
      "TechSupport                               -0.315461\n",
      "PhoneService                              -0.409633\n",
      "OnlineSecurity                            -0.431888\n",
      "Contract_Two year                         -0.705981\n",
      "InternetService_0                         -0.836557\n",
      "tenure                                    -2.867899\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Model 1 - All Features\n",
    "model1 = LogisticRegression()\n",
    "fit2 = model1.fit(x_train,y_train)\n",
    "predict_model1 = model1.predict(x_test)\n",
    "print(\"Model 1 - Accuracy: \",metrics.accuracy_score(y_test,predict_model1))\n",
    "print(\"Model 1 - ROC: \",roc_auc_score(y_test,predict_model1))\n",
    "print(\"Model 1 - Recall Score: \",recall_score(y_test,predict_model1))\n",
    "print(\"Model 1 - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_model1))\n",
    "print(\"Model 1 - Classification Report: \\n\", classification_report(y_test,predict_model1))\n",
    "weights1 = pd.Series(model1.coef_[0], index=x.columns.values)\n",
    "print(\"Model 1 - Weights:\\n\", weights1.sort_values(ascending = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Accuracy:  0.7892122072391767\n",
      "Model 2 - ROC:  0.6943296410536925\n",
      "Model 2 - Recall Score:  0.4844559585492228\n",
      "Model 2 - Confusion Matrix: \n",
      " [[925  98]\n",
      " [199 187]]\n",
      "Model 2 - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1023\n",
      "           1       0.66      0.48      0.56       386\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.74      0.69      0.71      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n",
      "Model 2 - Weights:\n",
      " InternetService_Fiber optic       0.988027\n",
      "Contract_Month-to-month           0.816076\n",
      "PaymentMethod_Electronic check    0.522160\n",
      "MonthlyCharges                    0.229578\n",
      "Contract_Two year                -0.818525\n",
      "InternetService_0                -0.830917\n",
      "tenure                           -2.170806\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Model 2 - Features ['tenure', 'MonthlyCharges', 'TotalCharges', 'InternetService_0', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_Two year', 'PaymentMethod_Electronic check']\n",
    "model2_features=['tenure', 'MonthlyCharges', 'InternetService_0', \n",
    "                 'InternetService_Fiber optic', 'Contract_Month-to-month', \n",
    "                 'Contract_Two year', 'PaymentMethod_Electronic check']\n",
    "\n",
    "x_train_model2=x_train[model2_features]\n",
    "x_test_model2=x_test[model2_features]\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "fit2 = model2.fit(x_train_model2,y_train)\n",
    "predict_model2 = model2.predict(x_test_model2)\n",
    "print(\"Model 2 - Accuracy: \",metrics.accuracy_score(y_test,predict_model2))\n",
    "print(\"Model 2 - ROC: \",roc_auc_score(y_test,predict_model2))\n",
    "print(\"Model 2 - Recall Score: \",recall_score(y_test,predict_model2))\n",
    "print(\"Model 2 - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_model2))\n",
    "print(\"Model 2 - Classification Report: \\n\", classification_report(y_test,predict_model2))\n",
    "weights2 = pd.Series(model2.coef_[0], index=x_train_model2.columns.values)\n",
    "print(\"Model 2 - Weights:\\n\", weights2.sort_values(ascending = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Accuracy:  0.7785663591199432\n",
      "Model 3 - ROC:  0.6805456368802516\n",
      "Model 3 - Recall Score:  0.4637305699481865\n",
      "Model 3 - Confusion Matrix: \n",
      " [[918 105]\n",
      " [207 179]]\n",
      "Model 3 - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.85      1023\n",
      "           1       0.63      0.46      0.53       386\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.68      0.69      1409\n",
      "weighted avg       0.77      0.78      0.77      1409\n",
      "\n",
      "Model 3 - Weights:\n",
      " InternetService_Fiber optic    1.068643\n",
      "Contract_Month-to-month        0.886151\n",
      "MonthlyCharges                 0.298494\n",
      "Contract_Two year             -0.863665\n",
      "InternetService_0             -0.937093\n",
      "tenure                        -2.264741\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - Features ['tenure', 'TotalCharges', 'InternetService_0', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_Two year']\n",
    "model3_features=['tenure', 'MonthlyCharges', 'InternetService_0', \n",
    "                 'InternetService_Fiber optic', 'Contract_Month-to-month', \n",
    "                 'Contract_Two year']\n",
    "\n",
    "x_train_model3=x_train[model3_features]\n",
    "x_test_model3=x_test[model3_features]\n",
    "\n",
    "model3 = LogisticRegression()\n",
    "fit3 = model3.fit(x_train_model3,y_train)\n",
    "predict_model3 = model3.predict(x_test_model3)\n",
    "print(\"Model 3 - Accuracy: \",metrics.accuracy_score(y_test,predict_model3))\n",
    "print(\"Model 3 - ROC: \",roc_auc_score(y_test,predict_model3))\n",
    "print(\"Model 3 - Recall Score: \",recall_score(y_test,predict_model3))\n",
    "print(\"Model 3 - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_model3))\n",
    "print(\"Model 3 - Classification Report: \\n\", classification_report(y_test,predict_model3))\n",
    "weights3 = pd.Series(model3.coef_[0], index=x_train_model3.columns.values)\n",
    "print(\"Model 3 - Weights:\\n\", weights3.sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - Accuracy:  0.8026969481902059\n",
      "Model 4 - ROC:  0.7165213053145528\n",
      "Model 4 - Recall Score:  0.5259067357512953\n",
      "Model 4 - Confusion Matrix: \n",
      " [[928  95]\n",
      " [183 203]]\n",
      "Model 4 - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      1023\n",
      "           1       0.68      0.53      0.59       386\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.76      0.72      0.73      1409\n",
      "weighted avg       0.79      0.80      0.79      1409\n",
      "\n",
      "Model 4 - Weights:\n",
      " InternetService_Fiber optic       1.468734\n",
      "Contract_Month-to-month           1.048091\n",
      "PaymentMethod_Electronic check    0.481241\n",
      "StreamingMovies                   0.408612\n",
      "StreamingTV                       0.386843\n",
      "InternetService_0                -1.174945\n",
      "MonthlyCharges                   -1.487988\n",
      "tenure                           -2.298676\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Model 4 - Features ['tenure', 'StreamingTV', 'StreamingMovies', 'MonthlyCharges', 'TotalCharges', 'InternetService_0', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_Two year', 'PaymentMethod_Electronic check']\n",
    "model4_features=['tenure', 'StreamingTV', 'StreamingMovies', 'MonthlyCharges', \n",
    "                  'InternetService_0', 'InternetService_Fiber optic', \n",
    "                 'Contract_Month-to-month', 'PaymentMethod_Electronic check']\n",
    "x_train_model4=x_train[model4_features]\n",
    "x_test_model4=x_test[model4_features]\n",
    "\n",
    "model4 = LogisticRegression()\n",
    "fit4 = model4.fit(x_train_model4,y_train)\n",
    "predict_model4 = model4.predict(x_test_model4)\n",
    "print(\"Model 4 - Accuracy: \",metrics.accuracy_score(y_test,predict_model4))\n",
    "print(\"Model 4 - ROC: \",roc_auc_score(y_test,predict_model4))\n",
    "print(\"Model 4 - Recall Score: \",recall_score(y_test,predict_model4))\n",
    "print(\"Model 4 - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_model4))\n",
    "print(\"Model 4 - Classification Report: \\n\", classification_report(y_test,predict_model4))\n",
    "weights4 = pd.Series(model4.coef_[0], index=x_train_model4.columns.values)\n",
    "print(\"Model 4 - Weights:\\n\", weights4.sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Comparison\n",
    "\n",
    "We have built 10 to 15 models iteratively and want to present below four models for comparison which has good accuracy and precision.\n",
    "\n",
    "| Model | No of Features | Accuracy |Precision (No Churn)| Precision (Churn)| ROC | Recall Score |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |----------- |\n",
    "| Model 1| 27 Features(All) | 79%| 84% | 67% | 69% | 0.48|\n",
    "| Model 2| 6 Features | 78%| 82% | 66% | 69% | 0.48|\n",
    "| Model 3| 4 Features | 77%| 82% | 63% | 68% | 0.48|\n",
    "| Model 4| 7 Features | 80%| 84% | 68% | 71% | 0.52|\n",
    "\n",
    "We want to select Model 4 as Final model which has better accuracy, good churn precision, ROC and Recall Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Hyper Parameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Parameter Tuning - No Weights - Accuracy:  0.8026969481902059\n",
      "Hyper Parameter Tuning - No Weights - ROC:  0.7165213053145528\n",
      "Hyper Parameter Tuning - No Weights - Recall Score:  0.5259067357512953\n",
      "Hyper Parameter Tuning - No Weights - Confusion Matrix: \n",
      " [[928  95]\n",
      " [183 203]]\n",
      "Hyper Parameter Tuning - No Weights - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      1023\n",
      "           1       0.68      0.53      0.59       386\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.76      0.72      0.73      1409\n",
      "weighted avg       0.79      0.80      0.79      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Model with default weights\n",
    "final_features=['tenure', 'StreamingTV', 'StreamingMovies', 'MonthlyCharges', \n",
    "                  'InternetService_0', 'InternetService_Fiber optic', \n",
    "                 'Contract_Month-to-month', 'PaymentMethod_Electronic check']\n",
    "x_train_final_model=x_train[final_features]\n",
    "x_test_final_model=x_test[final_features]\n",
    "\n",
    "log_reg_ht_model1 = LogisticRegression(random_state=1234, class_weight=None)\n",
    "log_reg_ht_fit1 = log_reg_ht_model1.fit(x_train_final_model,y_train)\n",
    "predict_ht_model1 = log_reg_ht_model1.predict(x_test_final_model)\n",
    "print(\"Hyper Parameter Tuning - No Weights - Accuracy: \",metrics.accuracy_score(y_test,predict_ht_model1))\n",
    "print(\"Hyper Parameter Tuning - No Weights - ROC: \",roc_auc_score(y_test,predict_ht_model1))\n",
    "print(\"Hyper Parameter Tuning - No Weights - Recall Score: \",recall_score(y_test,predict_ht_model1))\n",
    "print(\"Hyper Parameter Tuning - No Weights - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_ht_model1))\n",
    "print(\"Hyper Parameter Tuning - No Weights - Classification Report: \\n\", classification_report(y_test,predict_ht_model1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Churn: \n",
      " 0    0.73463\n",
      "1    0.26537\n",
      "Name: Churn, dtype: float64\n",
      "Hyper Parameter Tuning - With Weights - Accuracy:  0.7466288147622427\n",
      "Hyper Parameter Tuning - With Weights - ROC:  0.5440173927136989\n",
      "Hyper Parameter Tuning - With Weights - Recall Score:  0.09585492227979274\n",
      "Hyper Parameter Tuning - With Weights - Confusion Matrix: \n",
      " [[1015    8]\n",
      " [ 349   37]]\n",
      "Hyper Parameter Tuning - With Weights - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85      1023\n",
      "           1       0.82      0.10      0.17       386\n",
      "\n",
      "    accuracy                           0.75      1409\n",
      "   macro avg       0.78      0.54      0.51      1409\n",
      "weighted avg       0.77      0.75      0.66      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Model with Weights\n",
    "\n",
    "# check the distribution\n",
    "print(\"Distribution of Churn: \\n\", df['Churn'].value_counts()/df.shape[0])\n",
    "w = {0:73, 1:26}\n",
    "\n",
    "\n",
    "log_reg_ht_model2 = LogisticRegression(random_state=1234, class_weight=w)\n",
    "log_reg_ht_fit2 = log_reg_ht_model2.fit(x_train_final_model,y_train)\n",
    "predict_ht_model2 = log_reg_ht_model2.predict(x_test_final_model)\n",
    "print(\"Hyper Parameter Tuning - With Weights - Accuracy: \",metrics.accuracy_score(y_test,predict_ht_model2))\n",
    "print(\"Hyper Parameter Tuning - With Weights - ROC: \",roc_auc_score(y_test,predict_ht_model2))\n",
    "print(\"Hyper Parameter Tuning - With Weights - Recall Score: \",recall_score(y_test,predict_ht_model2))\n",
    "print(\"Hyper Parameter Tuning - With Weights - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_ht_model2))\n",
    "print(\"Hyper Parameter Tuning - With Weights - Classification Report: \\n\", classification_report(y_test,predict_ht_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.33421052631578946, 1: 0.6657894736842105}}\n",
      "Hyper Parameter Tuning - With Weights GridSearch - Accuracy:  0.7778566359119943\n",
      "Hyper Parameter Tuning - With Weights GridSearch - ROC:  0.7599081235216952\n",
      "Hyper Parameter Tuning - With Weights GridSearch - Recall Score:  0.7202072538860104\n",
      "Hyper Parameter Tuning - With Weights GridSearch - Confusion Matrix: \n",
      " [[818 205]\n",
      " [108 278]]\n",
      "Hyper Parameter Tuning - With Weights GridSearch - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      1023\n",
      "           1       0.58      0.72      0.64       386\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.73      0.76      0.74      1409\n",
      "weighted avg       0.80      0.78      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Model with Weights GridSearch\n",
    "# define weights\n",
    "\n",
    "w = np.linspace(0.05, 0.95, 20)\n",
    "grid = GridSearchCV(estimator=LogisticRegression(),\n",
    "                    param_grid={'class_weight': [{0: x, 1: 1.0-x} for x in w]},\n",
    "                    scoring='f1',cv=3)\n",
    "grid_result = grid.fit(x, y)\n",
    "print(\"Best parameters :\", grid_result.best_params_)\n",
    "\n",
    "w3={0: 0.33421052631578946, 1: 0.6657894736842105}\n",
    "\n",
    "log_reg_ht_model3 = LogisticRegression(random_state=1234, class_weight=w3)\n",
    "log_reg_ht_fit3 = log_reg_ht_model3.fit(x_train_final_model,y_train)\n",
    "predict_ht_model3 = log_reg_ht_model3.predict(x_test_final_model)\n",
    "print(\"Hyper Parameter Tuning - With Weights GridSearch - Accuracy: \",metrics.accuracy_score(y_test,predict_ht_model3))\n",
    "print(\"Hyper Parameter Tuning - With Weights GridSearch - ROC: \",roc_auc_score(y_test,predict_ht_model3))\n",
    "print(\"Hyper Parameter Tuning - With Weights GridSearch - Recall Score: \",recall_score(y_test,predict_ht_model3))\n",
    "print(\"Hyper Parameter Tuning - With Weights GridSearch - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_ht_model3))\n",
    "print(\"Hyper Parameter Tuning - With Weights GridSearch - Classification Report: \\n\", classification_report(y_test,predict_ht_model3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Hyper Parameter Tuning Results\n",
    "\n",
    "We did parameter tuning for the final model and here are the results\n",
    "\n",
    "| Parameter Tuning Method | Accuracy |Precision (No Churn)| Precision (Churn)| ROC | Recall Score |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |\n",
    "| No Weights | 80%| 84% | 67% | 71% | 0.54|\n",
    "| With Weights | 74%| 74% | 82% | 54% | 0.90|\n",
    "| Weights GridSearch | 77%| 88% | 58% | 75% | 0.72|\n",
    "\n",
    "\n",
    "We selected the parameter tuning method with weights. This models offers greater churn precision which is our objective, by sacrifing little accuracy and has better recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model 1 - Accuracy:  0.7955997161107168\n",
      "SVM Model 1 - ROC:  0.701954780970325\n",
      "SVM Model 1 - Recall Score:  0.4948186528497409\n",
      "SVM Model 1 - Confusion Matrix: \n",
      " [[930  93]\n",
      " [195 191]]\n",
      "SVM Model 1 - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1023\n",
      "           1       0.67      0.49      0.57       386\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.75      0.70      0.72      1409\n",
      "weighted avg       0.78      0.80      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic SVM Model with no hyper parameters and with all features\n",
    "svm_model1= SVC()\n",
    "svm_model1.fit(x_train,y_train)\n",
    "predict_svm_model1 = svm_model1.predict(x_test) \n",
    "print(\"SVM Model 1 - Accuracy: \",metrics.accuracy_score(y_test,predict_svm_model1))\n",
    "print(\"SVM Model 1 - ROC: \",roc_auc_score(y_test,predict_svm_model1))\n",
    "print(\"SVM Model 1 - Recall Score: \",recall_score(y_test,predict_svm_model1))\n",
    "print(\"SVM Model 1 - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_svm_model1))\n",
    "print(\"SVM Model 1 - Classification Report: \\n\", classification_report(y_test,predict_svm_model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model 2 - Accuracy:  0.7835344215755855\n",
      "SVM Model 2 - ROC:  0.6879998379246247\n",
      "SVM Model 2 - Recall Score:  0.47668393782383417\n",
      "SVM Model 2 - Confusion Matrix: \n",
      " [[920 103]\n",
      " [202 184]]\n",
      "SVM Model 2 - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1023\n",
      "           1       0.64      0.48      0.55       386\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.73      0.69      0.70      1409\n",
      "weighted avg       0.77      0.78      0.77      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic SVM Model with no hyper parameters and with Final features (selected as part of feature selection)\n",
    "svm_model2= SVC()\n",
    "svm_model2.fit(x_train_final_model,y_train)\n",
    "predict_svm_model2 = svm_model2.predict(x_test_final_model) \n",
    "\n",
    "print(\"SVM Model 2 - Accuracy: \",metrics.accuracy_score(y_test,predict_svm_model2))\n",
    "print(\"SVM Model 2 - ROC: \",roc_auc_score(y_test,predict_svm_model2))\n",
    "print(\"SVM Model 2 - Recall Score: \",recall_score(y_test,predict_svm_model2))\n",
    "print(\"SVM Model 2 - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_svm_model2))\n",
    "print(\"SVM Model 2 - Classification Report: \\n\", classification_report(y_test,predict_svm_model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Estimators : SVC(C=1000, gamma=0.1)\n",
      "SVM Model HyperParameter Tuning - Accuracy:  0.794889992902768\n",
      "SVM Model HyperParameter Tuning - ROC:  0.7038857571199206\n",
      "SVM Model HyperParameter Tuning - Recall Score:  0.5025906735751295\n",
      "SVM Model HyperParameter Tuning - Confusion Matrix: \n",
      " [[926  97]\n",
      " [192 194]]\n",
      "SVM Model HyperParameter Tuning - Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1023\n",
      "           1       0.67      0.50      0.57       386\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.75      0.70      0.72      1409\n",
      "weighted avg       0.78      0.79      0.79      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with Hyper Parameter Tuning - Grid Search\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']} \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True)\n",
    "grid.fit(x_train_final_model, y_train)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(\"Best Parameter :\", grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(\"Best Estimators :\",grid.best_estimator_)\n",
    "\n",
    "# Best Parameter : {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "# Best Estimators : SVC(C=1000, gamma=0.1)\n",
    "\n",
    "predict_svm_ht = grid.predict(x_test_final_model)\n",
    "\n",
    "print(\"SVM Model HyperParameter Tuning - Accuracy: \",metrics.accuracy_score(y_test,predict_svm_ht))\n",
    "print(\"SVM Model HyperParameter Tuning - ROC: \",roc_auc_score(y_test,predict_svm_ht))\n",
    "print(\"SVM Model HyperParameter Tuning - Recall Score: \",recall_score(y_test,predict_svm_ht))\n",
    "print(\"SVM Model HyperParameter Tuning - Confusion Matrix: \\n\", metrics.confusion_matrix(y_test,predict_svm_ht))\n",
    "print(\"SVM Model HyperParameter Tuning - Classification Report: \\n\", classification_report(y_test,predict_svm_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model Comparisons -\n",
    "\n",
    "| Model | Accuracy |Precision (No Churn)| Precision (Churn)| ROC | Recall Score |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |\n",
    "| SVM + All Features + No Hyper Parameter Tuning | 79%| 83% | 67% | 70% | 0.49|\n",
    "| SVM + Selected Features + No Hyper Parameter Tuning | 78%| 82% | 64% | 68% | 0.47|\n",
    "| SVM + Selected Features + Hyper Parameter Tuning  | 79%| 83% | 67% | 70% | 0.50|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "1. The main objective of this classification study is to predict and classify customer who are likely to churn.\n",
    "2. The dataset is very imbalanced dataset with 73% no churn and 26% as churn. This is taken into account during model selection and hyper tuning phases.\n",
    "3. The approach we have taken to model building is to run feature selection first, iteratively build multiple models based on the features, weights, eliminating correlated features and selecting final model that offer better metrics and then hyper tune it.\n",
    "4. Hyper Parameter Tuning was done based on some intuition and trail and error method.\n",
    "\n",
    "### Model Comparision\n",
    "1. Since we have an imbalanced dataset, using accuracy score as evaluation metrics is not a good measure of classifier performance. In such cases giving priority to Churn precision which is our objective and ROCs are good inidicator. This is approach followed in model selection.\n",
    "2. Below are the two final models we like to present.\n",
    "\n",
    "| Model | Accuracy |Precision (No Churn)| Precision (Churn)| ROC | Recall Score |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |\n",
    "| Logistic Regression + Selected Features + Hyper Parameter Tuning (Weights) | 74%| 74% | 82% | 54% | 0.90|\n",
    "| SVM + Selected Features + Hyper Parameter Tuning(Gamma, rbf)  | 79%| 83% | 67% | 70% | 0.50|\n",
    "\n",
    "3. We chose Logistic Regression model from the above models since it offered better churn precision by sacrificing little accuracy.\n",
    "4. This model will help in predicting and classifying the customer who are likely to churn with more accuracy.\n",
    "\n",
    "### Interpretation of Weights \n",
    "TBD..............\n",
    "We can see that some variables have a negative relation to our predicted variable (Churn), while some have positive relation. Negative relation means that likeliness of churn decreases with that variable. Let us summarize some of the interesting features below:\n",
    "\n",
    "As we saw in our EDA, having a monthly contract reduces chances of churn. monthly contract along with tenure have the most negative relation with Churn as predicted by logistic regressions Having DSL internet service also reduces the proability of Churn Lastly, total charges, monthly contracts, fibre optic internet services and seniority can lead to higher churn rates. This is interesting because although fibre optic services are faster, customers are likely to churn because of it. I think we need to explore more to better understad why this is happening. Any hypothesis on the above would be really helpful!\n",
    "\n",
    "### Insights from Support Vectors\n",
    "TBD.............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
